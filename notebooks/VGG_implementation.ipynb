{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTMAPV/0aiuxbH5Y7t8oof"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"q0cJr2Wg40oH"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4HYlcntcFa3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672374924360,"user_tz":-330,"elapsed":32004,"user":{"displayName":"Rakshat Shetty","userId":"05533257500087246041"}},"outputId":"73524b65-eb22-47fb-db69-275f21f2481d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split"],"metadata":{"id":"HN8fLw_REIQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","matplotlib.rcParams['figure.facecolor'] = '#ffffff'"],"metadata":{"id":"XwD-ZVl7H3Nk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.datasets import ImageFolder\n","import torchvision.transforms as transforms"],"metadata":{"id":"NNF0Fz4oEJ5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stats = ([0.485, 0.456, 0.406],\n"," [0.229, 0.224, 0.225])"],"metadata":{"id":"gKvzD1VtS4oX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0dCkAiAMcWaU"},"outputs":[],"source":["train_tfms = transforms.Compose([transforms.Resize((227, 227)),\n","                          transforms.RandomHorizontalFlip(), \n","                          transforms.ToTensor(), \n","                          transforms.Normalize(*stats,inplace=True)\n","                        ])\n","valid_tfms = transforms.Compose([transforms.Resize((227, 227)), transforms.ToTensor(), transforms.Normalize(*stats)\n","                        ])\n","test_tfms = transforms.Compose([transforms.Resize((227, 227)), transforms.ToTensor(), transforms.Normalize(*stats)\n","                        ])\n","           "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ood1fp5kVUZk"},"outputs":[],"source":["data_dir = \"/content/drive/MyDrive/Final year Project/dataset\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sz-kp2B8cBXp"},"outputs":[],"source":["train_ds = ImageFolder(data_dir+'/train', train_tfms)\n","val_ds = ImageFolder(data_dir+'/val', valid_tfms)\n","test_ds = ImageFolder(data_dir+'/test', test_tfms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZPFWDKzeAKy"},"outputs":[],"source":["batch_size = 16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7EWNxG0Z606","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672376085363,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rakshat Shetty","userId":"05533257500087246041"}},"outputId":"c4c4d1f8-8e5f-4c2c-858e-a08d9eb668dc"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n","val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"]},{"cell_type":"code","source":["import torch.nn as nn"],"metadata":{"id":"GIin7vXD3eQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"t_WehgfJFStr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(output, labels):\n","  _, preds = torch.max(output, dim=1)\n","  return (torch.sum(preds==labels).item()/len(preds))\n","\n","\n","class ImageClassificationBase(nn.Module):\n","  def training_step(self, batch):\n","    images, labels = batch\n","    out = self(images)\n","    loss = F.cross_entropy(out, labels)\n","    return loss\n","\n","\n","  def validation_step(self, batch):\n","    images, labels = batch\n","    out = self(images)\n","    loss = F.cross_entropy(out, labels)\n","    acc = accuracy(out, labels)\n","    return {'val_loss': loss.detach(), 'val_acc': torch.tensor(acc)}\n","\n","  def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","\n","\n","  def epoch_end(self, epoch, result):\n","    print(\"Epoch {}: train_loss: {:.4f} val_loss: {:.4f}  val_acc: {:.4f}\".format(\n","      epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))\n","    # print((epoch+1), result)\n"],"metadata":{"id":"v1GwhzVYDXiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision.models as models"],"metadata":{"id":"ursWBxgKJ4_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_ds.classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jSFsG5tSPo6","executionInfo":{"status":"ok","timestamp":1672376086908,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rakshat Shetty","userId":"05533257500087246041"}},"outputId":"85cc8c8b-26f5-473b-b65a-574a3ae676dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["class VGG_19(ImageClassificationBase):\n","    def __init__(self):\n","        super().__init__()\n","        # Use a pretrained model\n","        self.network = models.vgg19_bn(pretrained=True)\n","        # Replace last layer\n","        num_ftrs = self.network.classifier[6].in_features\n","        self.network.fc = nn.Linear(num_ftrs, len(train_ds.classes))\n","    \n","    def forward(self, xb):\n","        return torch.sigmoid(self.network(xb))\n","\n","\n"],"metadata":{"id":"vWhAJvgmJ6tJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = VGG_19()"],"metadata":{"id":"EF4sQcvlSRr2","executionInfo":{"status":"ok","timestamp":1672376089951,"user_tz":-330,"elapsed":2108,"user":{"displayName":"Rakshat Shetty","userId":"05533257500087246041"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"35515b2a-c224-45b7-b346-6b82a4c6ba1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)"],"metadata":{"id":"qm8xh3qbSVJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = get_default_device()\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhXSRAVm353y","executionInfo":{"status":"ok","timestamp":1672376089952,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rakshat Shetty","userId":"05533257500087246041"}},"outputId":"998b40bf-918d-4926-8e24-023783180de2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["train_dl = DeviceDataLoader(train_dl, device)\n","val_dl = DeviceDataLoader(val_dl, device)\n","to_device(model, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHHmupgq372b","executionInfo":{"status":"ok","timestamp":1672376090608,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rakshat Shetty","userId":"05533257500087246041"}},"outputId":"a13677fd-d2da-4d94-b5ae-9a5895b49c00"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG_19(\n","  (network): VGG(\n","    (features): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (9): ReLU(inplace=True)\n","      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (12): ReLU(inplace=True)\n","      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (16): ReLU(inplace=True)\n","      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (19): ReLU(inplace=True)\n","      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (22): ReLU(inplace=True)\n","      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (25): ReLU(inplace=True)\n","      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (29): ReLU(inplace=True)\n","      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (32): ReLU(inplace=True)\n","      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (35): ReLU(inplace=True)\n","      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (38): ReLU(inplace=True)\n","      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (42): ReLU(inplace=True)\n","      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (45): ReLU(inplace=True)\n","      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (48): ReLU(inplace=True)\n","      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (51): ReLU(inplace=True)\n","      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","    (classifier): Sequential(\n","      (0): Linear(in_features=25088, out_features=4096, bias=True)\n","      (1): ReLU(inplace=True)\n","      (2): Dropout(p=0.5, inplace=False)\n","      (3): Linear(in_features=4096, out_features=4096, bias=True)\n","      (4): ReLU(inplace=True)\n","      (5): Dropout(p=0.5, inplace=False)\n","      (6): Linear(in_features=4096, out_features=1000, bias=True)\n","    )\n","    (fc): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def early_stopping_and_saving_model(val_loss,path = None):\n","  if path != None and val_loss < 1.50:\n","    torch.save(model, path)\n","  elif val_loss < 1.4925:\n","    return True \n","    \n","\n","def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n","                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","    \n","    # Set up cutom optimizer with weight decay\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n","    # Set up one-cycle learning rate scheduler\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n","                                                steps_per_epoch=len(train_loader))\n","    \n","    for epoch in range(epochs):\n","        # Training Phase \n","        model.train()\n","        train_losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            \n","            # # Gradient clipping\n","            # if grad_clip: \n","            #     nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","            \n","            optimizer.step()\n","            optimizer.zero_grad()\n","            \n","            # Record & update learning rate\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","        \n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        result['lrs'] = lrs\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","\n","        #early stopping\n","        if early_stopping_and_saving_model(result['val_loss'], path = \"/content/drive/MyDrive/Final year Project/31_dec_150.pt\") == True:\n","          break\n","    return history"],"metadata":{"id":"3hV7Hd0w39cc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = to_device(VGG_19(), device)"],"metadata":{"id":"TVyu1-hk4B7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"EDhBLjdg4XuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate(model, val_dl)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pdj8YsNS4DXC","executionInfo":{"status":"ok","timestamp":1672376120499,"user_tz":-330,"elapsed":24172,"user":{"displayName":"Rakshat Shetty","userId":"05533257500087246041"}},"outputId":"0f599c44-87f3-4630-a59c-4f620a10dc59"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'val_loss': 7.051745414733887, 'val_acc': 0.0}"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["epochs = 25\n","max_lr = 0.0005\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam\n","\n","history = fit_one_cycle(num_epochs, lr, model, train_dl, val_dl, opt_func)"],"metadata":{"id":"L8T3dkcO4EwB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4b14f80-a0c3-4b2e-e0cc-c2ba06dd8876"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1: train_loss: 5.9770 val_loss: 5.9188  val_acc: 0.1650\n","Epoch 2: train_loss: 5.9187 val_loss: 5.9188  val_acc: 0.1500\n","Epoch 3: train_loss: 5.9188 val_loss: 5.9188  val_acc: 0.1500\n","Epoch 4: train_loss: 5.9186 val_loss: 5.9188  val_acc: 0.1500\n","Epoch 5: train_loss: 5.9186 val_loss: 5.9188  val_acc: 0.1500\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"W79ufwwVTSKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_accuracies(history):\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs');\n","\n","plot_accuracies(history)"],"metadata":{"id":"cN1ZOVnf4GyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_losses(history):\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs');\n","\n","plot_losses(history)"],"metadata":{"id":"5g5pWDr-4I5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/Final year Project/model_state_28_dec.pt\""],"metadata":{"id":"nscX9nji4xqr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLLm-pIyJp_W"},"outputs":[],"source":["torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","source":["torch.save(model, \"/content/drive/MyDrive/Final year Project/full_model_28_dec.pt\")"],"metadata":{"id":"QG_XtckvAlHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vuOPvnfaUzjO"},"execution_count":null,"outputs":[]}]}